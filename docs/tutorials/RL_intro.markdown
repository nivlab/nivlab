---
layout: default
title: Reinforcement learning tutorials
parent: Tutorials
permalink: /tutorials/RL/

nav_order: 2
---

A 3-part tutorial on basic reinforcement learning algorithms for across-trial and within-trial associative learning, both pavlovian and instrumental.

The [first part](https://github.com/spisupat/RL-tutorials/blob/main/Associative_learning_tutorial.ipynb) covers Rescorla-Wagner learning, a classic error-based algorithm for associating stimuli with rewards across trials.

The [second part](https://github.com/spisupat/RL-tutorials/blob/main/Temporal_difference_learning_tutorial.ipynb) covers Temporal-Difference learning, which allows for learning temporal predictions of value within trials and second-order associations.

The [third part](https://github.com/spisupat/RL-tutorials/blob/main/Instrumental_learning_tutorial.ipynb) covers three different model-free RL algorithms for learning valuable actions: Actor-critic learning, Q-learning and SARSA.

Each part of the tutorial is a jupyter notebook (can be opened on Colab) containing a brief theory overview and questions with starter code, followed by solutions.



[All code](https://github.com/spisupat/RL-tutorials){: .btn }
